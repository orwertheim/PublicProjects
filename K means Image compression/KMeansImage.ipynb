{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K-Means Image Compression\n",
        "\n",
        "In this notebook, we demonstrate how to compress an image using the K-Means clustering algorithm. The key idea is to reduce the number of unique colors in the image, thereby decreasing storage size while preserving visual quality.\n"
      ],
      "metadata": {
        "id": "bF-A8YpQuOvi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rlvxwuz-uKLS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import os\n",
        "import importlib\n",
        "import time\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing Configurations\n",
        "\n",
        "You can modify some default values to experiment with the notebook. The configurable parameters include:\n",
        "\n",
        "- **K** (currently set to 16): The number of clusters (colors) the image will be compressed to.  \n",
        "- **K2** (currently set to 3): An alternative number of clusters for compression.  \n",
        "- **ImageURL**: You can provide your own **Google Drive** Image URL.\n"
      ],
      "metadata": {
        "id": "XSirPIcEaD6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 16\n",
        "K2 = 3\n",
        "ImageURL = None#Replace None with: '<Your Google Drive URL>'"
      ],
      "metadata": {
        "id": "VhRUTiw8aEY8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading Required Files\n",
        "\n",
        "The `upload_file` function helps keep the notebook organized. We will use it later to upload `utils.py`, which contains plotting methods, and a sample image (`.png`) for experimentation.\n"
      ],
      "metadata": {
        "id": "n_8VjstFYEIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file(f_name, override=False, external_image=False):\n",
        "  url = f'https://raw.githubusercontent.com/orwertheim/PublicProjects/main/K%20means%20Image%20compression/{f_name}'\n",
        "\n",
        "  if external_image:\n",
        "    if 'drive.google.com/file/d/' in f_name:\n",
        "            # Extract the file ID\n",
        "            file_id = f_name.split('/file/d/')[1].split('/')[0]\n",
        "            print(f\"Detected Google Drive file with ID: {file_id}\")\n",
        "\n",
        "            destination = 'image.png'\n",
        "            if utils.download_from_gdrive(file_id, destination):\n",
        "                return destination\n",
        "            else:\n",
        "                return None\n",
        "    else:\n",
        "      print('Not a Google Drive Image URL!')\n",
        "      return None\n",
        "\n",
        "  if override or not os.path.exists(f_name):\n",
        "    timestamp = int(time.time())\n",
        "    url = f'{url}?t={timestamp}'\n",
        "\n",
        "  response = requests.get(url)\n",
        "  if response.status_code == 200:\n",
        "      with open(f_name, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "  else:\n",
        "    print(f'Error response: {response.status_code}')\n",
        "  return f_name  # Return the existing filename\n",
        ""
      ],
      "metadata": {
        "id": "D_1U5LwkxUps"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload_file('utils.py', override=True)\n",
        "import utils"
      ],
      "metadata": {
        "id": "JJ_etTBQ6r-F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Image Data\n",
        "\n",
        "As with any machine learning task, we first need to understand our data. Below is the original image we will be working with.\n"
      ],
      "metadata": {
        "id": "ChSRcX2JYgjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"colorImage1.png\"\n",
        "if ImageURL is None:\n",
        "  upload_file('colorImage1.png')\n",
        "else:\n",
        "  filename = upload_file(ImageURL, external_image=True)\n",
        "\n",
        "original_img = plt.imread(filename)\n",
        "original_img = original_img[:, :, :3]  # Keep only the first 3 channels remove transparancy\n",
        "\n",
        "# Limit the image resolution to reduce compute time\n",
        "if(original_img.shape[0] > 250):\n",
        "  # Calculate the new height (rows)\n",
        "  new_height = 250\n",
        "  aspect_ratio = original_img.shape[1] / original_img.shape[0]\n",
        "  new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "  # Resize the image\n",
        "  original_img = cv2.resize(original_img, (new_width, new_height))\n",
        "\n",
        "utils.display_images([original_img],['Original Image'])"
      ],
      "metadata": {
        "id": "Kleob1P-xbF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine the shape and contents of the image data.\n"
      ],
      "metadata": {
        "id": "ji-QkRd2Y3P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The image shape is: {original_img.shape}')\n",
        "print(f'The Image is in RGB format, the content of the first five pixel is: {original_img[0,:5]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DU1kJRpWH0L",
        "outputId": "57571110-3a9a-4122-d778-ec07b92838ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image shape is: (250, 202, 3)\n",
            "The Image is in RGB format, the content of the first five pixel is: [[0.87058824 0.25490198 0.23529412]\n",
            " [0.9137255  0.30980393 0.30980393]\n",
            " [0.99607843 0.40784314 0.45490196]\n",
            " [0.8980392  0.34509805 0.41960785]\n",
            " [0.92941177 0.40784314 0.5137255 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's visualize the color distribution of the pixels in our image.\n"
      ],
      "metadata": {
        "id": "hjwLcmsFY7x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utils.plot_rgb_3d(original_img, title='Original Image Color Distribution')"
      ],
      "metadata": {
        "id": "PvbwZa2mxnYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Means Algorithm Overview\n",
        "\n",
        "K-Means clustering operates as follows:\n",
        "\n",
        "1. **Initialize**: Select $K$ random centroids, each with the same dimensionality as the data points.  \n",
        "2. **Assignment Step**: Assign each data point to the closest centroid based on Euclidean distance.  \n",
        "3. **Update Step**: Recompute each centroid as the mean of the assigned data points.  \n",
        "4. **Repeat**: Iterate the assignment and update steps until convergence.\n",
        "\n",
        "K-Means is widely used for clustering both structured (tabular) and unstructured data, such as images. In this case, we apply it to image compression by grouping similar pixel colors.\n"
      ],
      "metadata": {
        "id": "CThgIXDGZFK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a function to find the closest centroid for each data point.  \n",
        "**Note**: Vectorizing computations significantly improves efficiency by reducing processing time.\n"
      ],
      "metadata": {
        "id": "CFcrbghaaS0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_centroids(X, centroids):\n",
        "    \"\"\"\n",
        "    Computes the centroid memberships for every example\n",
        "\n",
        "    Args:\n",
        "        X (ndarray): (m, n) Input values\n",
        "        centroids (ndarray): (K, n) centroids\n",
        "\n",
        "    Returns:\n",
        "        idx (array_like): (m,) closest centroids\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the squared Euclidean distance between each example and each centroid\n",
        "    # Broadcasting: X (m, n) and centroids (K, n) => (m, K, n)\n",
        "    diff = X[:, np.newaxis, :] - centroids  # (m, 1, n) - (K, n) => (m, K, n)\n",
        "    sq_dist = np.sum(diff**2, axis=2)  # (m, K) squared distances between each example and each centroid\n",
        "\n",
        "    # Find the index of the closest centroid (the one with the minimum distance)\n",
        "    idx = np.argmin(sq_dist, axis=1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "XcjocsgMy4p3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recomputing centroids based on their assigned data points.\n"
      ],
      "metadata": {
        "id": "GpDtFTGwbCi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_centroids(X, idx, K):\n",
        "    \"\"\"\n",
        "    Returns the new centroids by computing the means of the\n",
        "    data points assigned to each centroid.\n",
        "\n",
        "    Args:\n",
        "        X (ndarray):   (m, n) Data points\n",
        "        idx (ndarray): (m,) Array containing index of closest centroid for each\n",
        "                       example in X. Concretely, idx[i] contains the index of\n",
        "                       the centroid closest to example i\n",
        "        K (int):       number of centroids\n",
        "\n",
        "    Returns:\n",
        "        centroids (ndarray): (K, n) New centroids computed\n",
        "    \"\"\"\n",
        "\n",
        "    m, n = X.shape\n",
        "    centroids = np.zeros((K, n))\n",
        "\n",
        "    #add each example features to the centroid it belongs to\n",
        "    np.add.at(centroids, idx, X)\n",
        "\n",
        "    #count how many examples for each centroid\n",
        "    counts = np.bincount(idx, minlength=K).reshape(K,1)\n",
        "\n",
        "    #prevent zero divition\n",
        "    counts[counts == 0]=1\n",
        "\n",
        "    #calculate mean\n",
        "    centroids = centroids/counts\n",
        "\n",
        "    return centroids\n"
      ],
      "metadata": {
        "id": "Ki7NoUanGFwC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost Function for K-Means\n",
        "\n",
        "The cost function for K-Means clustering is the **Mean Squared Error (MSE)** between each data point and its assigned centroid. It helps evaluate the quality of the clustering solution.\n",
        "\n",
        "$$\n",
        "J = \\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} \\mathbb{1}(i, k) \\cdot \\| x_i - \\mu_k \\|^2\n",
        "$$\n",
        "\n",
        "Where:  \n",
        "- $x_i$ is the $i$-th data point,  \n",
        "- $\\mu_k$ is the $k$-th centroid,  \n",
        "- $\\mathbb{1}(i, k)$ is an indicator function (1 if $x_i$ is assigned to centroid $k$, otherwise 0),  \n",
        "- $m$ is the total number of data points,  \n",
        "- $K$ is the number of centroids,  \n",
        "- $\\| x_i - \\mu_k \\|^2$ is the squared error.\n"
      ],
      "metadata": {
        "id": "PtcYBqYRIAun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, centroids, idx):\n",
        "    \"\"\"\n",
        "    Computes the cost function for K-Means clustering.\n",
        "\n",
        "    Args:\n",
        "        X (ndarray): (m, n) Input data, where m is the number of data points and n is the number of features.\n",
        "        centroids (ndarray): (K, n) Centroids of the clusters, where K is the number of centroids.\n",
        "        idx (ndarray): (m,) Index array where each element is the index of the centroid assigned to the corresponding data point.\n",
        "\n",
        "    Returns:\n",
        "        J (float): The computed cost (sum of squared errors) for the given centroids and assignments.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the number of data points and centroids\n",
        "    m = X.shape[0]\n",
        "\n",
        "    # Efficiently compute the squared distances using broadcasting\n",
        "    # X (m, n) -> subtract from the corresponding centroid (centroids[idx] will have shape (m, n))\n",
        "    # The subtraction is done element-wise and then squared\n",
        "    diff = X - centroids[idx]  # Shape: (m, n)\n",
        "    squared_diff = np.sum(diff**2, axis=1)  # Sum the squared differences along the feature axis, result is shape (m,)\n",
        "\n",
        "    # The cost is the average of the squared distances\n",
        "    J = np.sum(squared_diff) / m\n",
        "\n",
        "    return J"
      ],
      "metadata": {
        "id": "-I1MYzshG5dr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enhanced K-Means Implementation\n",
        "\n",
        "The K-Means implementation below incorporates two key improvements:\n",
        "\n",
        "1. **Smart Initialization**: Instead of random selection, centroids are chosen from the data points, improving convergence speed.  \n",
        "2. **Multiple Runs & Best Selection**: The algorithm is executed multiple times with different initializations, selecting the best result based on the cost function.\n",
        "\n",
        "Choosing an appropriate $K$ can be done using the **elbow method**, but in many cases—including ours—it is practical to experiment with different values and choose the one that works best.\n"
      ],
      "metadata": {
        "id": "KWNXNKvDbwEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_kMeans(X, initial_centroids, max_iters=10, prints=False):\n",
        "    \"\"\"\n",
        "    Runs the K-Means algorithm on data matrix X, where each row of X\n",
        "    is a single example\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize values\n",
        "    m, n = X.shape\n",
        "    K = initial_centroids.shape[0]\n",
        "    centroids = initial_centroids\n",
        "    idx = np.zeros(m)\n",
        "    # Run K-Means\n",
        "    last_cost=-1\n",
        "\n",
        "    #for i in tqdm(range(max_iters), desc=\"K-Means iterations\", unit=\"item\"):\n",
        "    for i in range(max_iters):\n",
        "        # For each example in X, assign it to the closest centroid\n",
        "        idx = find_closest_centroids(X, centroids)\n",
        "\n",
        "        # Given the memberships, compute new centroids\n",
        "        centroids = compute_centroids(X, idx, K)\n",
        "        last_cost=compute_cost(X,centroids, idx)\n",
        "        #Output progress\n",
        "        if prints:\n",
        "          print(f\"K-Means iteration: {i}/{max_iters-1}, cost: {last_cost}\")\n",
        "    return centroids, idx, last_cost"
      ],
      "metadata": {
        "id": "BDAXBTWEK7m5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting random centroids from the data points.\n"
      ],
      "metadata": {
        "id": "4ALJjrsxc1Do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kMeans_init_centroids(X, K):\n",
        "    \"\"\"\n",
        "    This function initializes K centroids that are to be\n",
        "    used in K-Means on the dataset X\n",
        "\n",
        "    Args:\n",
        "        X (ndarray): Data points\n",
        "        K (int):     number of centroids/clusters\n",
        "\n",
        "    Returns:\n",
        "        centroids (ndarray): Initialized centroids\n",
        "    \"\"\"\n",
        "\n",
        "    # Randomly reorder the indices of examples\n",
        "    randidx = np.random.permutation(X.shape[0])\n",
        "\n",
        "    # Take the first K examples as centroids\n",
        "    centroids = X[randidx[:K]]\n",
        "\n",
        "    return centroids"
      ],
      "metadata": {
        "id": "Syk5YGo7Qd_D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping our image into a matrix, where each row represents a pixel and consists of three columns corresponding to the R, G, and B color channels."
      ],
      "metadata": {
        "id": "fVZJJlR0dCCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_img = np.reshape(original_img, (original_img.shape[0] * original_img.shape[1], 3))"
      ],
      "metadata": {
        "id": "2CmySES4QwUW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will run K-Means with 300 different initializations for both $K = 16$ and $K = 3$."
      ],
      "metadata": {
        "id": "sSAHTBlbdTJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run your K-Means algorithm on this data\n",
        "# You should try different values of K and max_iters here\n",
        "\n",
        "max_iters = 10\n",
        "\n",
        "initializations_count = 300\n",
        "pairs = list(zip([K, K2] * initializations_count, list(range(initializations_count)) * 2))\n",
        "centroids_ar = []\n",
        "cost_ar = []\n",
        "idx_ar = []\n",
        "\n",
        "best_k2_centroid = None\n",
        "best_k2_cost = float('inf')\n",
        "best_k2_idx = None\n",
        "\n",
        "for k_value, init in tqdm(pairs, desc=\"K-Means Runs\", unit=\"Run\"):\n",
        "  # Using the function you have implemented above.\n",
        "  initial_centroids = kMeans_init_centroids(X_img, k_value)\n",
        "  # Run K-Means - this can take a couple of minutes depending on K and max_iters\n",
        "  centroids, idx, cost = run_kMeans(X_img, initial_centroids, max_iters)\n",
        "  if k_value == K:\n",
        "    centroids_ar.append(centroids); idx_ar.append(idx); cost_ar.append(cost)\n",
        "  elif cost < best_k2_cost:\n",
        "    best_k2_cost = cost\n",
        "    best_k2_centroid = centroids\n",
        "    best_k2_idx = idx\n",
        "\n"
      ],
      "metadata": {
        "id": "9FGIRCKULV3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the importance of running K-Means multiple times, we will plot the mean squared distance of each pixel from its assigned centroid. This will help us visualize the variance across different runs."
      ],
      "metadata": {
        "id": "RAiJ3tuvdsyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_range = (np.min(cost_ar)-0.001, np.max(cost_ar)+0.001)\n",
        "utils.plot_costs(cost_ar, y_label=\"Mean Squared Distance of Pixels to Their Centroids\", x_label='K-Means Run (Initialization Attempt)', title='Pixel Similarity to Centroids Across Multiple K-Means Runs', y_lim=y_range)"
      ],
      "metadata": {
        "id": "YoVlaA5YLbIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now visualize the pixel distributions for the original image, the best and worst runs with $K = 16$, and the best run with $K = 3$. This comparison highlights the trade-off between lower $K$ values, which lead to higher compression, and higher $K$ values, which better preserve image quality."
      ],
      "metadata": {
        "id": "lyv-BdZFeN4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_centroids = centroids_ar[np.argmin(cost_ar)]\n",
        "best_centroids_idx = idx_ar[np.argmin(cost_ar)]\n",
        "\n",
        "worst_centroids = centroids_ar[np.argmax(cost_ar)]\n",
        "worst_centroids_idx = idx_ar[np.argmax(cost_ar)]\n",
        "\n",
        "#utils.plot_kMeans_RGB(X_img, best_centroids, best_centroids_idx, centroids2 = best_k2_centroid, idx2 = best_k2_idx, sample_size=1000000)\n",
        "utils.plot_kMeans_RGB(X_img, [best_centroids, worst_centroids, best_k2_centroid], [best_centroids_idx, worst_centroids_idx, best_k2_idx], ['Original colors',f'Pixel Colors Based on best run with {len(best_centroids)} Centroids',f'Pixel Colors Based on worst run with {len(best_centroids)} Centroids', f'Pixel Colors Based on {len(best_k2_centroid)} Centroids'] , sample_size=1000000)"
      ],
      "metadata": {
        "id": "iq1C3zhya0zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine the reconstructed images to understand the importance of running K-Means multiple times. By comparing the best and worst runs, we can clearly see the differences in image quality."
      ],
      "metadata": {
        "id": "3z257XtIewfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_image = np.reshape(best_centroids[best_centroids_idx],original_img.shape)\n",
        "\n",
        "\n",
        "\n",
        "worst_image = np.reshape(worst_centroids[worst_centroids_idx],original_img.shape)\n",
        "\n",
        "\n",
        "k2_image = np.reshape(best_k2_centroid[best_k2_idx],original_img.shape)\n",
        "\n",
        "utils.display_images([original_img, best_image, worst_image, k2_image],['Original Image', f'Best Clustering Image For {K} colors', f'Worst Clustering Image For {K} colors', f'Best Clustering Image For {K2} colors'])"
      ],
      "metadata": {
        "id": "QxmlN5Yjk28q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the colors selected for the best run with $K = 16$."
      ],
      "metadata": {
        "id": "-wxVNVpjfFei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utils.show_centroid_colors(best_centroids)"
      ],
      "metadata": {
        "id": "KA398TTJ5axq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the colors selected for the worst run with $K = 16$."
      ],
      "metadata": {
        "id": "KCbQ5RyifMg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utils.show_centroid_colors(worst_centroids)"
      ],
      "metadata": {
        "id": "eRa_rgF0FrLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the colors selected for the best run with $K = 3$."
      ],
      "metadata": {
        "id": "MfdvrPsGfOgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utils.show_centroid_colors(best_k2_centroid)"
      ],
      "metadata": {
        "id": "GAkK3kWxFxaa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}